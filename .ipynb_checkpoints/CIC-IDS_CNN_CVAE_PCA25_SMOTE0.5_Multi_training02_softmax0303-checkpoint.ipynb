{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6359a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3700cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy, kl_divergence\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PowerTransformer\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2a16b7",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"./cic_ids_smote03_pca25.csv\")\n",
    "#df = pd.read_csv(\"/Users/anchanghun/Downloads/CIC-Dataset/cleaned_improved_cicids2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044ef64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =pd.read_csv(\"D:/dataset/0219_Paper_Dataset/train_pca.csv\")\n",
    "X_test =pd.read_csv(\"D:/dataset/0219_Paper_Dataset/test_pca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4efb1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6378151, 26), (405464, 26))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f49293d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train['label']\n",
    "X_train = X_train.drop(labels='label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4af141de-1956-41a7-a800-d472d51a9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = X_test['label']\n",
    "X_test = X_test.drop(labels='label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed36d011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6378151, 25), (405464, 25))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "882dc9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6378151,), (405464,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "417d89f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, RepeatVector, Conv1D, Conv1DTranspose\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras_self_attention import SeqWeightedAttention, SeqSelfAttention\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d65d3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "179386/179386 [==============================] - 858s 5ms/step - loss: 8.8333 - ReconstructedOutput_accuracy: 0.6394 - ClassificationOutput_accuracy: 0.9995 - val_loss: 0.2083 - val_ReconstructedOutput_accuracy: 0.0137 - val_ClassificationOutput_accuracy: 0.9996\n",
      "Epoch 2/50\n",
      "179386/179386 [==============================] - 843s 5ms/step - loss: 8.8182 - ReconstructedOutput_accuracy: 0.6036 - ClassificationOutput_accuracy: 1.0000 - val_loss: 0.2161 - val_ReconstructedOutput_accuracy: 9.5952e-04 - val_ClassificationOutput_accuracy: 0.9954\n",
      "Epoch 3/50\n",
      "179386/179386 [==============================] - 894s 5ms/step - loss: 8.8180 - ReconstructedOutput_accuracy: 0.5723 - ClassificationOutput_accuracy: 1.0000 - val_loss: 0.2132 - val_ReconstructedOutput_accuracy: 0.0051 - val_ClassificationOutput_accuracy: 0.9984\n",
      "Epoch 4/50\n",
      "179386/179386 [==============================] - 1086s 6ms/step - loss: 8.8180 - ReconstructedOutput_accuracy: 0.5376 - ClassificationOutput_accuracy: 1.0000 - val_loss: 0.2149 - val_ReconstructedOutput_accuracy: 0.0073 - val_ClassificationOutput_accuracy: 0.9984\n",
      "Epoch 5/50\n",
      "179386/179386 [==============================] - 1093s 6ms/step - loss: 8.8178 - ReconstructedOutput_accuracy: 0.5357 - ClassificationOutput_accuracy: 1.0000 - val_loss: 0.2074 - val_ReconstructedOutput_accuracy: 0.0057 - val_ClassificationOutput_accuracy: 0.9988\n",
      "Epoch 6/50\n",
      "179386/179386 [==============================] - 1070s 6ms/step - loss: 8.8183 - ReconstructedOutput_accuracy: 0.5355 - ClassificationOutput_accuracy: 1.0000 - val_loss: 0.2079 - val_ReconstructedOutput_accuracy: 0.0078 - val_ClassificationOutput_accuracy: 0.9991\n",
      "Epoch 7/50\n",
      "179386/179386 [==============================] - 1120s 6ms/step - loss: 8.8180 - ReconstructedOutput_accuracy: 0.5369 - ClassificationOutput_accuracy: 1.0000 - val_loss: 0.2146 - val_ReconstructedOutput_accuracy: 0.0035 - val_ClassificationOutput_accuracy: 0.9983\n",
      "Epoch 8/50\n",
      " 35707/179386 [====>.........................] - ETA: 12:47 - loss: 8.8708 - ReconstructedOutput_accuracy: 0.5367 - ClassificationOutput_accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# 클래스 개수 (정상 + 공격 유형 개수)\n",
    "num_classes = 9  # 정상(1) + 8개 공격\n",
    "\n",
    "# 잠재 차원 및 중간 차원 설정\n",
    "latent_dim = 10\n",
    "inter_dim = 20\n",
    "\n",
    "# 샘플링 함수 (재매개변수화 트릭 사용)\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    batch_size = tf.shape(z_mean)[0]\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(0.5 * K.clip(z_log_sigma, -10, 10)) * epsilon\n",
    "\n",
    "# CVAE 손실 함수 (Gaussian MLP + Bernoulli MLP 반영)\n",
    "def cvae_loss(x, x_decoded_mean, z_mean, z_log_sigma, y_true, y_pred):\n",
    "    # Reconstruction Loss (Gaussian MLP 적용)\n",
    "    reconstruction_loss = K.mean(K.square(x - x_decoded_mean) + 1e-10)  # NaN 방지\n",
    "    \n",
    "    # KL Divergence (잠재 공간 학습 - Gaussian MLP)\n",
    "    kl_loss = -0.5 * K.sum(1 + K.clip(z_log_sigma, -10, 10) - K.square(z_mean) - K.exp(K.clip(z_log_sigma, -10, 10)), axis=-1)\n",
    "    kl_loss_weighted = kl_loss * 0.001  # KL 손실 가중치 적용\n",
    "\n",
    "    # Classification Loss (Bernoulli MLP 적용)\n",
    "    classification_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)  # 다중 분류\n",
    "    \n",
    "    # 총 손실 (Gaussian + Bernoulli)\n",
    "    total_loss = K.mean(reconstruction_loss + kl_loss_weighted + classification_loss)\n",
    "    return total_loss\n",
    "\n",
    "# CVAE 모델 정의 (Gaussian MLP + Bernoulli MLP)\n",
    "def cvae(X, y):\n",
    "    features = X.shape[1]  # 특징 수\n",
    "    input_x = Input(shape=(features,), name='InputFeatures')\n",
    "    input_y = Input(shape=(num_classes,), name='InputLabels')  # 라벨 추가\n",
    "\n",
    "    # CNN 기반 인코더\n",
    "    reshaped_input = layers.Reshape((features, 1))(input_x)\n",
    "    h = layers.Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding='same')(reshaped_input)\n",
    "    h = layers.Conv1D(filters=32, kernel_size=3, activation=\"relu\", padding='same')(h)\n",
    "    h = layers.Conv1D(filters=16, kernel_size=3, activation=\"relu\", padding='same')(h)\n",
    "    h = layers.Flatten()(h)\n",
    "    h = layers.Concatenate()([h, input_y])  # 라벨과 결합\n",
    "    h = layers.Dense(inter_dim, activation='relu')(h)\n",
    "\n",
    "    # Gaussian MLP (잠재 공간)\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(h)\n",
    "    z_log_sigma = layers.Dense(latent_dim, name='z_log_sigma')(h)\n",
    "    z = layers.Lambda(sampling, name='z')([z_mean, z_log_sigma])\n",
    "\n",
    "    # 디코더 (Gaussian MLP)\n",
    "    decoder_input = layers.Concatenate()([z, input_y])  # 잠재 벡터 + 라벨\n",
    "    decoder1 = layers.Dense(features * inter_dim)(decoder_input)\n",
    "    decoder1 = layers.Reshape((features, inter_dim))(decoder1)\n",
    "    decoder1 = layers.Conv1DTranspose(filters=16, kernel_size=3, activation=\"relu\", padding='same')(decoder1)\n",
    "    decoder1 = layers.Conv1DTranspose(filters=32, kernel_size=3, activation=\"relu\", padding='same')(decoder1)\n",
    "    decoder1 = layers.Conv1DTranspose(filters=64, kernel_size=3, activation=\"relu\", padding='same')(decoder1)\n",
    "    decoder1 = layers.Flatten()(decoder1)\n",
    "    x_decoded_mean = layers.Dense(features, activation='sigmoid', name='ReconstructedOutput')(decoder1)  # 최종 복원\n",
    "\n",
    "    # Bernoulli MLP (다중 분류)\n",
    "    classification_output = layers.Dense(num_classes, activation='softmax', name='ClassificationOutput')(h)\n",
    "\n",
    "    # 모델 생성\n",
    "    model = Model([input_x, input_y], [x_decoded_mean, classification_output])\n",
    "    model.add_loss(cvae_loss(input_x, x_decoded_mean, z_mean, z_log_sigma, input_y, classification_output))\n",
    "\n",
    "    return model\n",
    "\n",
    "# CVAE 학습 (정상 + 여러 공격 데이터 포함)\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train, num_classes)  # 라벨 원핫 인코딩\n",
    "model = cvae(X_train, y_train_onehot)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit([X_train, y_train_onehot], [X_train, y_train_onehot],  # Reconstruction + Classification\n",
    "                    shuffle=True, epochs=50, validation_split=0.1, batch_size=32,\n",
    "                    callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_shapes.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab395c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 테스트 데이터 라벨 원핫 인코딩\n",
    "y_test_onehot = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a65dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = np.sum(np.isin(X_test, X_train).all(axis=1))\n",
    "print(f\"Number of overlapping samples: {overlap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e3424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test unique values:\", np.unique(y_test))\n",
    "print(\"y_test_onehot shape:\", y_test_onehot.shape)\n",
    "print(\"Sample y_test_onehot:\", y_test_onehot[:5])  # 일부 샘플 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ccde41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 라벨 원-핫 인코딩 (y_test → one-hot)\n",
    "y_test_onehot = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c86595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 분류 예측 수행\n",
    "x_decoded_pred, y_pred_probs = model.predict([X_test, y_test_onehot])\n",
    "\n",
    "# 예측된 클래스 (가장 확률이 높은 클래스 선택)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# 실제 정답 클래스\n",
    "y_true_classes = np.argmax(y_test_onehot, axis=1)\n",
    "\n",
    "# 정확도 평가\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"테스트 정확도: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 상세 성능 보고서 (Precision, Recall, F1-score)\n",
    "print(\"\\n 분류 성능 보고서:\\n\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=[\"Normal\", \"Attack1\", \"Attack2\", \"Attack3\", \"Attack4\", \"Attack5\", \"Attack6\", \"Attack7\", \"Attack8\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Normal\", \"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\"], yticklabels=[\"Normal\", \"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\", \"A7\", \"A8\"])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe5b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# One-vs-All AUC 계산\n",
    "auc_score = roc_auc_score(y_test_onehot, y_pred_probs, multi_class='ovr')\n",
    "print(f\"다중 분류 AUC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8135f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습 과정 시각화\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d996f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test 없이 테스트 데이터만 사용하여 예측 수행\n",
    "_, y_pred_probs = model.predict([X_test, np.zeros_like(y_test_onehot)])  # 더미 라벨 입력\n",
    "\n",
    "# 최종 예측 클래스\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6649e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 분류 예측 수행\n",
    "x_decoded_pred, y_pred_probs = model.predict([X_test, y_test_onehot])\n",
    "\n",
    "# 예측된 클래스 (가장 확률이 높은 클래스 선택)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# 실제 정답 클래스\n",
    "y_true_classes = np.argmax(y_test_onehot, axis=1)\n",
    "\n",
    "# 정확도 평가\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"테스트 정확도: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 상세 성능 보고서 (Precision, Recall, F1-score)\n",
    "print(\"\\n분류 성능 보고서:\\n\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=[\"Normal\", \"Attack1\", \"Attack2\", \"Attack3\", \"Attack4\", \"Attack5\", \"Attack6\", \"Attack7\", \"Attack8\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0844b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# One-vs-All AUC 계산\n",
    "auc_score = roc_auc_score(y_test_onehot, y_pred_probs, multi_class='ovr')\n",
    "print(f\"다중 분류 AUC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff46b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 모델 예측\n",
    "x_decoded_pred, y_pred_probs = model.predict([X_test, y_test_onehot])\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "y_true_classes = np.argmax(y_test_onehot, axis=1)\n",
    "\n",
    "# 정확도 평가 및 상세 보고서 출력\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\" 테스트 정확도: {accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "target_names = [\"BENIGN\", \"DDoS\", \"DoS GoldenEye\", \"DoS Hulk\", \"DoS Slowhttptest\", \n",
    "                \"DoS Slowloris\", \"FTP-Patator\", \"Portscan\", \"SSH-Patator\"]\n",
    "\n",
    "print(\" 분류 성능 보고서:\\n\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=target_names))\n",
    "\n",
    "# Confusion Matrix 계산\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "# Confusion Matrix 시각화\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')  # Normalize by row\n",
    "    cm = np.round(cm, 2)  # Round to two decimals\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = sns.heatmap(cm, annot=True, fmt='.2f', cmap='gray', linewidths=0.5,\n",
    "                      xticklabels=labels, yticklabels=labels, cbar=False)\n",
    "    \n",
    "    # 강조 효과: 주요 값(대각선)과 높은 오차율 강조\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            value = cm[i, j]\n",
    "            color = 'white' if value > 0.5 else 'black'\n",
    "            ax.text(j + 0.5, i + 0.5, f'{value:.2f}',\n",
    "                    ha='center', va='center', color=color, fontsize=12)\n",
    "    \n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "# 예제 데이터 (y_true와 y_pred는 모델 결과를 대체해야 함)\n",
    "y_true = np.random.randint(0, 10, 100)\n",
    "y_pred = y_true.copy()\n",
    "y_pred[np.random.choice(len(y_pred), 10)] = np.random.randint(0, 10, 10)  # 일부 오류 추가\n",
    "\n",
    "labels = [\"Benign\", \"FTP-patator\", \"SSH-patator\", \"Hulk\", \"Slowhttptest\", \"Goldeneye\", \"Slowloris\", \"Portscan\", \"DDoS\", \"Unknown\"]\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78557ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3431e95e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e55a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
