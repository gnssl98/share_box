{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6359a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3700cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy, kl_divergence\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PowerTransformer\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2a16b7",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"./cic_ids_smote03_pca25.csv\")\n",
    "#df = pd.read_csv(\"/Users/anchanghun/Downloads/CIC-Dataset/cleaned_improved_cicids2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044ef64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =pd.read_csv(\"D:/dataset/0219_Paper_Dataset/train_pca.csv\")\n",
    "X_test =pd.read_csv(\"D:/dataset/0219_Paper_Dataset/test_pca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4efb1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6378151, 26), (405464, 26))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b81965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318909, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal = X_train[X_train['label'] == 0]\n",
    "X_train_normal.shape\n",
    "\n",
    "X_test_normal = X_test[X_test['label'] == 0]\n",
    "X_test_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f355b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_normal = X_train_normal['label']\n",
    "X_train_normal = X_train_normal.drop(labels='label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f49293d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train['label']\n",
    "X_train = X_train.drop(labels='label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4af141de-1956-41a7-a800-d472d51a9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = X_test['label']\n",
    "X_test = X_test.drop(labels='label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed36d011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6378151, 25), (405464, 25))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "882dc9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6378151,), (405464,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2760d6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1275631, 25)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4927aa60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405464, 25)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "417d89f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, RepeatVector, Conv1D, Conv1DTranspose\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras_self_attention import SeqWeightedAttention, SeqSelfAttention\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d65d3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " InputLabel (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 25)        50          ['InputLabel[0][0]']             \n",
      "                                                                                                  \n",
      " InputFeatures (InputLayer)     [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 25)           0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 50)           0           ['InputFeatures[0][0]',          \n",
      "                                                                  'flatten[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 50, 1)        0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 50, 64)       256         ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 50, 32)       6176        ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 50, 16)       1552        ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 800)          0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 20)           16020       ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 20)           420         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           210         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10)           210         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 10)           0           ['dense_2[0][0]',                \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 35)           0           ['lambda[0][0]',                 \n",
      "                                                                  'flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1000)         36000       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 50, 20)       0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_transpose (Conv1DTransp  (None, 50, 16)      976         ['reshape_1[0][0]']              \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " conv1d_transpose_1 (Conv1DTran  (None, 50, 32)      1568        ['conv1d_transpose[0][0]']       \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv1d_transpose_2 (Conv1DTran  (None, 50, 64)      6208        ['conv1d_transpose_1[0][0]']     \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 3200)         0           ['conv1d_transpose_2[0][0]']     \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 25)           80025       ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 10)          0           ['dense_3[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.square_1 (TFOpLambda)  (None, 10)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 10)          0           ['tf.__operators__.add[0][0]',   \n",
      " )                                                                'tf.math.square_1[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.exp (TFOpLambda)       (None, 10)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None, 10)          0           ['tf.math.subtract_1[0][0]',     \n",
      " )                                                                'tf.math.exp[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 25)           0           ['InputFeatures[0][0]',          \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  (None,)             0           ['tf.math.subtract_2[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.square (TFOpLambda)    (None, 25)           0           ['tf.math.subtract[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None,)              0           ['tf.math.reduce_sum_1[0][0]']   \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None,)             0           ['tf.math.square[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None,)             0           ['tf.math.multiply[0][0]']       \n",
      " )                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None,)             0           ['tf.math.reduce_sum[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  ()                  0           ['tf.__operators__.add_1[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " add_loss (AddLoss)             ()                   0           ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 149,671\n",
      "Trainable params: 149,671\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "28613/35878 [======================>.......] - ETA: 36s - loss: nan - accuracy: 0.1059"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, Model, Input\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "latent_dim = 10\n",
    "inter_dim = 20\n",
    "\n",
    "# Sampling function for reparameterization trick\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    batch_size = tf.shape(z_mean)[0]\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1.)\n",
    "    return z_mean + z_log_sigma * epsilon\n",
    "\n",
    "def vae_loss(x, x_decoded_mean, z_mean, z_log_sigma):\n",
    "    reconstruction_loss = K.sum(K.square(x - x_decoded_mean), axis=1)\n",
    "    kl_loss = -0.5 * K.sum(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    kl_loss_weighted = kl_loss * 0.0001  # KL 다이버전스 손실에 가중치 부여\n",
    "    total_loss = K.mean(reconstruction_loss + kl_loss_weighted)\n",
    "    return total_loss\n",
    "\n",
    "def cvae(X, labels):\n",
    "    features = X.shape[1]  # 2D 데이터이므로 timesteps는 필요 없고, features만 사용\n",
    "    input_x = Input(shape=(features,), name='InputFeatures')  # 2D 입력 (샘플, 특징)\n",
    "\n",
    "    input_label = Input(shape=(1,), name='InputLabel')  # Assumes binary or multi-class label\n",
    "\n",
    "    # Embed the label into the same shape as the input\n",
    "    embedded_label = layers.Embedding(input_dim=2, output_dim=features)(input_label)  # Adjust output_dim to match features\n",
    "    embedded_label = layers.Flatten()(embedded_label)\n",
    "\n",
    "    # Concatenate input_x and embedded_label\n",
    "    concatenated_input = layers.Concatenate()([input_x, embedded_label])\n",
    "\n",
    "    # Reshape for Conv1D layer (to 3D)\n",
    "    reshaped_input = layers.Reshape((features + embedded_label.shape[-1], 1))(concatenated_input)\n",
    "\n",
    "    # Encoder with CNN layers\n",
    "    h = layers.Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding='same')(reshaped_input)\n",
    "    h = layers.Conv1D(filters=32, kernel_size=3, activation=\"relu\", padding='same')(h)\n",
    "    h = layers.Conv1D(filters=16, kernel_size=3, activation=\"relu\", padding='same')(h)\n",
    "\n",
    "    # Flatten for dense layers (MLP)\n",
    "    h = layers.Flatten()(h)\n",
    "    h = layers.Dense(inter_dim, activation='relu')(h)\n",
    "    h = layers.Dense(inter_dim, activation='relu')(h)\n",
    "\n",
    "    # z layer\n",
    "    z_mean = layers.Dense(latent_dim)(h)\n",
    "    z_log_sigma = layers.Dense(latent_dim)(h)\n",
    "    z = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "    # Decoder\n",
    "    # Add the label to the latent space z\n",
    "    z_with_label = layers.Concatenate()([z, embedded_label])\n",
    "\n",
    "    # Expand for Conv1DTranspose layer\n",
    "    decoder1 = layers.Dense((features + embedded_label.shape[-1]) * inter_dim)(z_with_label)\n",
    "    decoder1 = layers.Reshape((features + embedded_label.shape[-1], inter_dim))(decoder1)\n",
    "\n",
    "    # Decoder with CNN layers\n",
    "    decoder1 = layers.Conv1DTranspose(filters=16, kernel_size=3, activation=\"relu\", padding='same')(decoder1)\n",
    "    decoder1 = layers.Conv1DTranspose(filters=32, kernel_size=3, activation=\"relu\", padding='same')(decoder1)\n",
    "    decoder1 = layers.Conv1DTranspose(filters=64, kernel_size=3, activation=\"relu\", padding='same')(decoder1)\n",
    "\n",
    "    # Flatten and final dense layer to reconstruct original features\n",
    "    decoder1 = layers.Flatten()(decoder1)\n",
    "    decoder1 = layers.Dense(features)(decoder1)\n",
    "    \n",
    "    model = Model([input_x, input_label], decoder1)\n",
    "    model.add_loss(vae_loss(input_x, decoder1, z_mean, z_log_sigma))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create CVAE model\n",
    "model = cvae(X_train_normal, y_train_normal)\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), metrics=['accuracy'])\n",
    "# Create an EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Compile and train the model with early stopping\n",
    "history = model.fit([X_train_normal, y_train_normal], X_train_normal,\n",
    "                    shuffle=True,\n",
    "                    epochs=50, \n",
    "                    validation_split=0.1,  \n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_shapes.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training losses\n",
    "fig, ax = plt.subplots(figsize=(14, 6), dpi=80)\n",
    "ax.plot(history['loss'], 'b', label='Train', linewidth=2)\n",
    "ax.plot(history['val_loss'], 'r', label='Validation', linewidth=2)\n",
    "ax.set_title('Model loss', fontsize=16)\n",
    "ax.set_ylabel('Loss (mae)')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78557ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(X):\n",
    "    flattened_X = np.empty((X.shape[0], X.shape[2]))  # sample x features array.\n",
    "    for i in range(X.shape[0]):\n",
    "        flattened_X[i] = X[i, (X.shape[1]-1), :]\n",
    "    return(flattened_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3431e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x_predictions = model.predict([X_test, y_test])\n",
    "#mse = np.mean(np.power(flatten(test_X_selected) - flatten(valid_x_predictions), 2), axis=1)\n",
    "\n",
    "mse = np.mean(np.power(X_test - valid_x_predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': y_test.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e55a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e38ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터프레임 준비\n",
    "true_class = error_df['true_class'].astype(str)\n",
    "reconstruction_error = error_df['reconstruction_error']\n",
    "\n",
    "# 박스 플롯 그리기\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.boxplot(\n",
    "    [reconstruction_error[true_class == cls] for cls in sorted(true_class.unique())],\n",
    "    labels=sorted(true_class.unique()),\n",
    "    showfliers=False,\n",
    "    vert=True,\n",
    "    patch_artist=True\n",
    ")\n",
    "\n",
    "plt.ylabel('Distribution')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "480efbfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'error_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Prepare the data for plotting\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m true_class_0 \u001b[38;5;241m=\u001b[39m \u001b[43merror_df\u001b[49m[error_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_class\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreconstruction_error\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m true_class_1 \u001b[38;5;241m=\u001b[39m error_df[error_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_class\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreconstruction_error\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create the figure and axes with a specified y-axis limit\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'error_df' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare the data for plotting\n",
    "true_class_0 = error_df[error_df['true_class'] == 0]['reconstruction_error']\n",
    "true_class_1 = error_df[error_df['true_class'] == 1]['reconstruction_error']\n",
    "\n",
    "# Create the figure and axes with a specified y-axis limit\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Add jitter to avoid overlapping points in the scatter plot\n",
    "x_0 = np.random.normal(1, 0.04, size=len(true_class_0))  # Jitter for class 0\n",
    "x_1 = np.random.normal(2, 0.04, size=len(true_class_1))  # Jitter for class 1\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.scatter(x_0, true_class_0, color='orange', alpha=0.6, edgecolor='black', label='Class 0')\n",
    "plt.scatter(x_1, true_class_1, color='blue', alpha=0.6, edgecolor='black', label='Class 1')\n",
    "\n",
    "# Set y-axis limit\n",
    "plt.ylim(0, 3000)\n",
    "\n",
    "# Set x-axis labels and adjust ticks\n",
    "plt.xticks([1, 2], ['0', '1'])\n",
    "plt.xlabel('True Class')\n",
    "\n",
    "# Set y-axis label and title\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.title('Reconstruction Error by True Class')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data for plotting\n",
    "true_class_0 = error_df[error_df['true_class'] == 0]['reconstruction_error']\n",
    "true_class_1 = error_df[error_df['true_class'] == 1]['reconstruction_error']\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Create a swarm plot equivalent using scatter plot with more jitter\n",
    "x_0 = np.random.normal(1, 0.1, size=len(true_class_0))  # Increased jitter for class 0\n",
    "x_1 = np.random.normal(2, 0.1, size=len(true_class_1))  # Increased jitter for class 1\n",
    "\n",
    "ax.scatter(x_0, true_class_0, color='blue', alpha=0.6, label='Class 0', edgecolor='w', s=50)\n",
    "ax.scatter(x_1, true_class_1, color='orange', alpha=0.6, label='Class 1', edgecolor='w', s=50)\n",
    "\n",
    "# Create boxplots\n",
    "ax.boxplot([true_class_0, true_class_1], positions=[1, 2], widths=0.6, patch_artist=True, \n",
    "           showfliers=False, boxprops=dict(facecolor='None', color='black'),\n",
    "           medianprops=dict(color='black'), whiskerprops=dict(color='black'))\n",
    "\n",
    "# Set x-axis labels\n",
    "ax.set_xticks([1, 2])\n",
    "ax.set_xticklabels(['Class 0', 'Class 1'])\n",
    "\n",
    "# Add a horizontal line at the threshold\n",
    "ax.axhline(y=0.03, xmin=0.0, xmax=1, dashes=(5, 5), color='red')\n",
    "\n",
    "# Adjust y-axis limit to make sure the threshold line is visible\n",
    "#ax.set_ylim(bottom=min(min(true_class_0), min(true_class_1)) - 0.01, \n",
    "#           top=max(max(true_class_0), max(true_class_1)) + 0.01)\n",
    "ax.set_ylim(bottom=0, top=3000)\n",
    "    \n",
    "# Set labels and title\n",
    "ax.set_ylabel('Reconstruction Error')\n",
    "ax.set_title('Reconstruction Error by Class')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67041510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the range of threshold values\n",
    "threshold_range = np.arange(2590, 2650, 1)\n",
    "\n",
    "# List to store F1 scores for each threshold\n",
    "f1_scores = []\n",
    "\n",
    "# Loop through each threshold and calculate F1 score\n",
    "for threshold in threshold_range:\n",
    "    y_pred = [0 if e < threshold else 1 for e in error_df.reconstruction_error.values]\n",
    "    f1 = f1_score(error_df.true_class, y_pred)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Find the threshold with the highest F1 score\n",
    "best_threshold = threshold_range[np.argmax(f1_scores)]\n",
    "best_f1_score = max(f1_scores)\n",
    "\n",
    "print(f\"Best threshold: {best_threshold}\")\n",
    "print(f\"Best F1 score: {best_f1_score}\")\n",
    "\n",
    "# Optionally, you can plot the F1 scores across the threshold range\n",
    "plt.plot(threshold_range, f1_scores, marker='o')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs Threshold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c764e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming you have already defined LABELS, threshold, and y_pred\n",
    "\n",
    "LABELS = [\"Attack\", \"Normal\"]\n",
    "\n",
    "y_pred = [0 if e < threshold else 1 for e in error_df.reconstruction_error.values]\n",
    "conf_matrix = confusion_matrix(error_df.true_class, y_pred)\n",
    "\n",
    "# Create the figure and axis\n",
    "plt.figure(figsize=(12, 12))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the confusion matrix using imshow\n",
    "cax = ax.matshow(conf_matrix, cmap=plt.cm.Blues)\n",
    "\n",
    "# Add color bar\n",
    "plt.colorbar(cax)\n",
    "\n",
    "# Set the labels for the axes\n",
    "ax.set_xticks(np.arange(len(LABELS)))\n",
    "ax.set_yticks(np.arange(len(LABELS)))\n",
    "\n",
    "ax.set_xticklabels(LABELS)\n",
    "ax.set_yticklabels(LABELS)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Predicted class')\n",
    "plt.ylabel('True class')\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "# Annotate the confusion matrix with the counts\n",
    "for i in range(len(LABELS)):\n",
    "    for j in range(len(LABELS)):\n",
    "        ax.text(j, i, format(conf_matrix[i, j], 'd'),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if conf_matrix[i, j] > conf_matrix.max() / 2 else \"black\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc563697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Assuming y_test and reconstruction_error have been defined\n",
    "fpr, tpr, thresholds = roc_curve(y_test, reconstruction_error)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7381cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If error_df.true_class is a nested structure, flatten it\n",
    "y_test = error_df.true_class.apply(lambda x: int(x[0][0]) if isinstance(x, list) else int(x))\n",
    "\n",
    "# Ensure y_pred is a list of integers\n",
    "y_pred = [0 if e < threshold else 1 for e in error_df.reconstruction_error.values]\n",
    "\n",
    "# Now calculate the metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
